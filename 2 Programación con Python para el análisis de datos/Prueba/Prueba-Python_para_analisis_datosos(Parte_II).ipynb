{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26cc96be",
   "metadata": {},
   "source": [
    "# Prueba - Python para el análisis de datos\n",
    "## Daniel Rojas Lopez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24dc6e5",
   "metadata": {},
   "source": [
    "### Ejercicio 1:\n",
    "   1. Genera una función llamada leer_tabla(tabla, engine) y utilízala para leer tablas\n",
    "completas desde la base de datos en dataframes independientes. Utilizando esta\n",
    "función, importa las siguientes tablas:\n",
    "- order\n",
    "- orderdetails\n",
    "- customers\n",
    "- products\n",
    "- employees\n",
    "2. Realiza el cruce entre los DataFrames, asegurándote de utilizar correctamente el\n",
    "parámetro validate para asegurar la integridad referencial.\n",
    "_ 1\n",
    "www.desafiolatam.com\n",
    "3. Agrega las siguientes columnas, considerando su nombre y la fórmula asociada\n",
    "- venta: quantityOrdered*priceEach\n",
    "- costo: quantityOrdered*buyPrice\n",
    "- ganancia: considerando las columnas anteriores\n",
    "4. ¿Cuál fue el total de ventas por línea de productos? Incluye una fila de totales.\n",
    "5. ¿Cuántos clientes distintos hicieron compras?\n",
    "6. ¿Existen clientes que aún no han hecho ninguna compra? ¿Cuántos son?\n",
    "7. Se solicita la creación de dos reportes, que respondan las preguntas dadas\n",
    "● ¿Cuáles fueron los 10 clientes que reportan mayores ventas brutas en dinero durante\n",
    "el año 2005? Genera un DataFrame y guárdalo en una tabla de Postgre llamada\n",
    "top_10_clientes_2005, en la que se especifique el nombre del cliente y su\n",
    "correspondiente venta, costo y ganancia.\n",
    "● ¿Cuál fue el top 10 de artículos más vendidos durante el año 2005? Genera un\n",
    "DataFrame y guárdalo en una tabla de Postgre llamada top_10_productos_2005, en la\n",
    "que se especifique el nombre del producto y su correspondiente venta, costo y\n",
    "ganancia.\n",
    "Para este punto debes aplicar el principio DRY, por lo que se deben utilizar funciones para\n",
    "realizar el filtrado por fechas, generar tablas pivote y escribir tabla en Postgre. Las funciones\n",
    "deben estar en un archivo separado llamado funciones.py y ser importadas al Jupyter\n",
    "Notebook. En este archivo se debe incluir:\n",
    "● Una función que permita filtrar un DataFrame por fechas, indicando dataframe,\n",
    "columna para filtrar, fecha inicio y fecha fin. La función debe retornar un DataFrame.\n",
    "● Una función que permita generar reportes dependiendo de parámetros de entrada\n",
    "como dataframe, filas, columnas, valores y medida (funcion_agrupadora). Utilizar\n",
    "fill_value = 0. Esta función debe retornar un DataFrame pivotado.\n",
    "● Una función que permita escribir en la base de datos a través del guardado de un\n",
    "DataFrame dependiendo de parámetros de entrada como DataFrame, nombre de la\n",
    "tabla, engine y comportamiento en caso de que exista la tabla (if_exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27329cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de datos conectada exitosamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\AppData\\Local\\Temp\\ipykernel_20372\\3293652894.py:45: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_table(tabla, engine)\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n        SELECT\n            name\n        FROM\n            sqlite_master\n        WHERE\n            type IN ('table', 'view')\n            AND name=?;\n        ': syntax error at or near \";\"\nLINE 8:             AND name=?;\n                              ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSyntaxError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:2664\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2663\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2664\u001b[39m     \u001b[43mcur\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[31mSyntaxError\u001b[39m: syntax error at or near \";\"\nLINE 8:             AND name=?;\n                              ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatabaseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     48\u001b[39m conn = coneccionBD()\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m#cargarBD(conn)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m dfOrdernes=\u001b[43mleer_tabla\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43morders\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m dfOrdernes.to_csv(\u001b[33m\"\u001b[39m\u001b[33morders.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# 2. Realiza el cruce entre los DataFrames, asegurándote de utilizar correctamente el parámetro validate para asegurar la integridad referencial.\u001b[39;00m\n\u001b[32m     62\u001b[39m \n\u001b[32m     63\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# ● Una función que permita generar reportes dependiendo de parámetros de entrada como dataframe, filas, columnas, valores y medida (funcion_agrupadora). Utilizar fill_value = 0. Esta función debe retornar un DataFrame pivotado.\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# ● Una función que permita escribir en la base de datos a través del guardado de un DataFrame dependiendo de parámetros de entrada como DataFrame, nombre de la tabla, engine y comportamiento en caso de que exista la tabla (if_exists).\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mleer_tabla\u001b[39m\u001b[34m(tabla, engine)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mleer_tabla\u001b[39m(tabla, engine):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtabla\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:387\u001b[39m, in \u001b[36mread_sql_table\u001b[39m\u001b[34m(table_name, con, schema, index_col, coerce_float, parse_dates, columns, chunksize, dtype_backend)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default\n\u001b[32m    386\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema=schema, need_transaction=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    388\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    390\u001b[39m     table = pandas_sql.read_table(\n\u001b[32m    391\u001b[39m         table_name,\n\u001b[32m    392\u001b[39m         index_col=index_col,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m         dtype_backend=dtype_backend,\n\u001b[32m    398\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:2855\u001b[39m, in \u001b[36mSQLiteDatabase.has_table\u001b[39m\u001b[34m(self, name, schema)\u001b[39m\n\u001b[32m   2844\u001b[39m wld = \u001b[33m\"\u001b[39m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2845\u001b[39m query = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   2846\u001b[39m \u001b[33mSELECT\u001b[39m\n\u001b[32m   2847\u001b[39m \u001b[33m    name\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2852\u001b[39m \u001b[33m    AND name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwld\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m;\u001b[39m\n\u001b[32m   2853\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2855\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.fetchall()) > \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\sql.py:2676\u001b[39m, in \u001b[36mSQLiteDatabase.execute\u001b[39m\u001b[34m(self, sql, params)\u001b[39m\n\u001b[32m   2673\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minner_exc\u001b[39;00m\n\u001b[32m   2675\u001b[39m ex = DatabaseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecution failed on sql \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2676\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mDatabaseError\u001b[39m: Execution failed on sql '\n        SELECT\n            name\n        FROM\n            sqlite_master\n        WHERE\n            type IN ('table', 'view')\n            AND name=?;\n        ': syntax error at or near \";\"\nLINE 8:             AND name=?;\n                              ^\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def coneccionBD():\n",
    "    # Conéctate a PostgreSQL (sin especificar una base de datos)\n",
    "    conn = psycopg2.connect(database=\"classicmodels\", #Es el nombre de la base de datos a la que te quieres conectar, postgres es por defecto\n",
    "                                user=\"postgres\", #Es el nombre de usuario que tiene permisos para conectarse a esa base de datos.\n",
    "                                password=\"postgres\", \n",
    "                                host=\"localhost\", #Indica dónde está alojada la base de datos. \"localhost\" significa que está en el mismo computador donde estás ejecutando el script de Python.\n",
    "                                port=\"5432\")    \n",
    "    print(\"Base de datos conectada exitosamente.\")\n",
    "    return conn\n",
    "    \n",
    "def cargarBD(conn):\n",
    "    #cargar el script sql para carga la base de datos\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    sql_file_path = \"classicmodels.sql\"\n",
    "\n",
    "    # Leer el archivo SQL y ejecutarlo\n",
    "    with open(sql_file_path, \"r\", encoding=\"utf-8\") as sql_file:\n",
    "        print(\"Leyendo el archivo SQL...\"+sql_file_path)  \n",
    "        sql_script = sql_file.read()  # Lee todo el contenido del archivo SQL\n",
    "        cursor.execute(sql_script)  # Ejecuta el script\n",
    "\n",
    "    conn.commit()  # Confirma los cambios\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Base de datos importada exitosamente.\")\n",
    "    return conn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1. Genera una función llamada leer_tabla(tabla, engine) y utilízala para leer tablas completas desde la base de datos en dataframes independientes. Utilizando esta función, importa las siguientes tablas:\n",
    "#- order\n",
    "#- orderdetails\n",
    "#- customers\n",
    "#- products\n",
    "#- employees\n",
    "def leer_tabla(tabla, engine):\n",
    "    df = pd.read_sql_table(tabla, engine)\n",
    "    return df\n",
    "\n",
    "conn = coneccionBD()\n",
    "#cargarBD(conn)\n",
    "\n",
    "\n",
    "dfOrdernes=leer_tabla(\"orders\", conn)\n",
    "dfOrdernes.to_csv(\"orders.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Realiza el cruce entre los DataFrames, asegurándote de utilizar correctamente el parámetro validate para asegurar la integridad referencial.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Agrega las siguientes columnas, considerando su nombre y la fórmula asociada\n",
    "# - venta: quantityOrdered*priceEach\n",
    "# - costo: quantityOrdered*buyPrice\n",
    "# - ganancia: considerando las columnas anteriores\n",
    "# 4. ¿Cuál fue el total de ventas por línea de productos? Incluye una fila de totales.\n",
    "# 5. ¿Cuántos clientes distintos hicieron compras?\n",
    "# 6. ¿Existen clientes que aún no han hecho ninguna compra? ¿Cuántos son?\n",
    "# 7. Se solicita la creación de dos reportes, que respondan las preguntas dadas\n",
    "# ● ¿Cuáles fueron los 10 clientes que reportan mayores ventas brutas en dinero durante el año 2005? Genera un DataFrame y guárdalo en una tabla de Postgre llamada top_10_clientes_2005, en la que se especifique el nombre del cliente y su correspondiente venta, costo y ganancia.\n",
    "# ● ¿Cuál fue el top 10 de artículos más vendidos durante el año 2005? Genera un DataFrame y guárdalo en una tabla de Postgre llamada top_10_prod   uctos_2005, en la que se especifique el nombre del producto y su correspondiente venta, costo y ganancia.  Para este punto debes aplicar el principio DRY, por lo que se deben utilizar funciones parrealizar el filtrado por fechas, generar tablas pivote y escribir tabla en Postgre. Las funciones deben estar en un archivo separado llamado funciones.py y ser importadas al Jupyter Notebook. En este archivo se debe incluir:\n",
    "# ● Una función que permita filtrar un DataFrame por fechas, indicando dataframe, columna para filtrar, fecha inicio y fecha fin. La función debe retornar un DataFrame.\n",
    "# ● Una función que permita generar reportes dependiendo de parámetros de entrada como dataframe, filas, columnas, valores y medida (funcion_agrupadora). Utilizar fill_value = 0. Esta función debe retornar un DataFrame pivotado.\n",
    "# ● Una función que permita escribir en la base de datos a través del guardado de un DataFrame dependiendo de parámetros de entrada como DataFrame, nombre de la tabla, engine y comportamiento en caso de que exista la tabla (if_exists).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
